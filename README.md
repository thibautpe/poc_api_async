# POC API Asynchrone avec Timeout (Spring Boot, Gatling)

Ce projet est un Proof of Concept (POC) d√©montrant la mise en ≈ìuvre d'une API asynchrone en Java Spring Boot, avec gestion avanc√©e des timeouts c√¥t√© appelant, simulation d'API externe lente, et tests de charge automatis√©s avec Gatling.

## Pr√©requis

- Java 11 ou sup√©rieur
- Maven 3.6 ou sup√©rieur

## Installation

1. Cloner le projet
2. Se placer dans le r√©pertoire du projet
3. Compiler le projet :
```bash
mvn clean install
```

## Lancer l'application

Pour d√©marrer l'application sur le port 8081 :
```bash
mvn spring-boot:run
```

L'application sera accessible √† l'adresse : http://localhost:8081

## Endpoints disponibles

### Endpoint principal
- URL : `/handler`
- M√©thode : GET
- Param√®tres :
  - `delay` : d√©lai en millisecondes (optionnel, d√©faut : 0)
- Exemple : http://localhost:8081/handler?delay=100

## Tests manuels

Vous pouvez tester l'API manuellement avec curl :

```bash
# Test sans d√©lai
curl http://localhost:8081/handler

# Test avec un d√©lai de 100ms
curl http://localhost:8081/handler?delay=100

# Test avec un d√©lai de 500ms
curl http://localhost:8081/handler?delay=500
```

## Tests automatis√©s

Pour ex√©cuter les tests unitaires :
```bash
mvn test
```

## Tests de charge avec Gatling

Le projet inclut des tests de charge avec Gatling. Le sc√©nario de test comprend trois phases :
1. Augmentation progressive jusqu'√† 5 utilisateurs (5 secondes)
2. Charge constante de 2 requ√™tes par seconde (10 secondes)
3. Augmentation jusqu'√† 10 utilisateurs (5 secondes)

### Lancer les tests de charge

1. S'assurer que l'application est en cours d'ex√©cution
2. Dans un nouveau terminal, ex√©cuter :
```bash
mvn gatling:test
```

### Consulter les r√©sultats

Les rapports de test sont g√©n√©r√©s dans le dossier :
```
target/gatling/[nom-du-test]-[timestamp]/index.html
```

Ouvrez ce fichier HTML dans votre navigateur pour voir les r√©sultats d√©taill√©s, incluant :
- Temps de r√©ponse
- D√©bit
- Nombre de requ√™tes
- Taux d'erreurs
- Graphiques de performance

## Consultation du dashboard Gatling

Apr√®s chaque test de charge, Gatling g√©n√®re automatiquement un rapport HTML interactif.

### O√π trouver le rapport ?

Le rapport se trouve dans le dossier :
```
target/gatling/[nom-du-test]-[timestamp]/index.html
```
Ouvrez ce fichier dans votre navigateur pour acc√©der au dashboard.

### Que contient le dashboard ?
- **Nombre total de requ√™tes** (OK/KO)
- **Temps de r√©ponse** (min, max, moyenne, percentiles)
- **Taux d'erreur**
- **D√©bit (requ√™tes/seconde)**
- **Distribution des temps de r√©ponse**
- **Graphiques d'√©volution dans le temps**
- **R√©partition des erreurs**

### Conseils d'analyse
- Surveillez les courbes de latence et les pics d'erreur
- Analysez les percentiles (95e, 99e) pour d√©tecter les lenteurs
- V√©rifiez la stabilit√© du d√©bit
- Utilisez les graphiques pour comparer plusieurs campagnes

### Exemple de visualisation
![Exemple dashboard Gatling](https://gatling.io/docs/current/img/report/response_time_distribution.png)

Pour des analyses avanc√©es, vous pouvez exporter les r√©sultats ou les int√©grer dans des outils comme Grafana, Kibana ou Excel.

## Structure du projet

```
src/
‚îú‚îÄ‚îÄ main/
‚îÇ   ‚îú‚îÄ‚îÄ java/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ com/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ example/
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ demo/
‚îÇ   ‚îÇ               ‚îú‚îÄ‚îÄ DemoApplication.java
‚îÇ   ‚îÇ               ‚îî‚îÄ‚îÄ HandlerController.java
‚îÇ   ‚îî‚îÄ‚îÄ resources/
‚îÇ       ‚îî‚îÄ‚îÄ application.properties
‚îî‚îÄ‚îÄ test/
    ‚îî‚îÄ‚îÄ java/
        ‚îî‚îÄ‚îÄ com/
            ‚îî‚îÄ‚îÄ example/
                ‚îî‚îÄ‚îÄ demo/
                    ‚îú‚îÄ‚îÄ DemoApplicationTests.java
                    ‚îî‚îÄ‚îÄ HandlerSimulation.java
```

## Configuration

Le fichier `application.properties` contient la configuration de base :
- Port : 8081
- Logging : configur√© pour afficher les IDs de requ√™te et les dur√©es

## Logs

Les logs incluent :
- ID de requ√™te (format : 4 chiffres)
- D√©lai de traitement
- Dur√©e totale de la requ√™te
- Nombre de requ√™tes actives 

## Gestion des timeouts et erreurs HTTP 504

### C√¥t√© serveur
- Si l'API externe met plus de 2000 ms √† r√©pondre, le contr√¥leur retourne une r√©ponse JSON avec le code HTTP 504 (Gateway Timeout)¬†:

```json
{
  "requestId": "0001",
  "error": "EXTERNAL_API_TIMEOUT",
  "message": "Request timeout after 2000ms (requested delay: 2300ms)",
  "status": "TIMEOUT"
}
```

### C√¥t√© Gatling
- Les r√©ponses HTTP 504 sont d√©sormais comptabilis√©es comme des erreurs (KO) dans les rapports Gatling.
- Seules les r√©ponses HTTP 200 sont consid√©r√©es comme des succ√®s (OK).
- Vous pouvez retrouver le d√©tail des erreurs dans la section "Errors" du rapport Gatling, par exemple¬†:

```
> status.find.is(200), but actually found 504   15 (65%)
```

- Le taux d'erreur affich√© dans le dashboard Gatling refl√®te donc bien les timeouts comme des √©checs. 

## üìã Critique du POC API Asynchrone

### Points forts

1. **Gestion explicite du timeout c√¥t√© appelant**  
   Le timeout est configurable et bien propag√© jusqu'√† l'appel asynchrone. La gestion du timeout via `CompletableFuture` et un `ScheduledExecutorService` est claire et robuste.

2. **S√©paration des responsabilit√©s**  
   Le contr√¥leur orchestre la logique m√©tier et la gestion des erreurs. Le service d'appel externe encapsule la logique d'appel et de gestion du timeout.

3. **Tests automatis√©s et charge**  
   Pr√©sence de tests unitaires/IT et d'un sc√©nario Gatling pour la charge et la robustesse. Les tests couvrent les cas de succ√®s et d'√©chec (timeout).

4. **Documentation claire**  
   Les docs et README expliquent bien le fonctionnement, les param√®tres, et la logique de timeout. Les rapports Gatling sont accompagn√©s d'un README explicatif.

5. **Logs d√©taill√©s**  
   Les logs permettent de suivre chaque √©tape, y compris les cas de timeout et de r√©ponses tardives.

---

### Points d'am√©lioration ou d'attention

1. **Gestion des ressources (threads/executor)**  
   Le POC cr√©e un nouvel `ExecutorService` et un `ScheduledExecutorService` √† chaque appel.  
   ‚Üí En production, il vaut mieux injecter un pool partag√© (via Spring ou config) pour √©viter la fuite de threads.

2. **Nettoyage des threads**  
   Les `ScheduledExecutorService` sont shutdown apr√®s usage, mais attention √† ne pas en cr√©er trop en charge r√©elle.

3. **Gestion des exceptions**  
   La gestion des exceptions est bonne, mais tu pourrais affiner les types d'erreurs pour distinguer timeout, erreurs r√©seau, etc.

4. **Extensibilit√©**  
   Pour un usage r√©el, pr√©voir la configuration du pool, du timeout, et de l'URL externe via des propri√©t√©s Spring.

5. **Observabilit√©**  
   Pour la prod, ajouter des m√©triques (Micrometer/Prometheus) sur les timeouts, les r√©ponses tardives, etc.

6. **S√©curit√©**  
   Pour un POC ce n'est pas critique, mais en prod, attention √† la validation des entr√©es et √† la gestion des erreurs expos√©es.

7. **Tests**  
   Les tests sont bien faits pour le POC. Pour la prod, ajouter des tests de mont√©e en charge plus longs, et des tests de r√©silience (coupure r√©seau, etc.).

8. **Code style**  
   Le code est propre, bien comment√©, et les imports sont bien g√©r√©s.

---

### En r√©sum√©

- **Pour un POC, la solution est tr√®s propre, p√©dagogique et r√©aliste.**
- **Pour un passage en production**, il faudra industrialiser la gestion des pools de threads, la configuration, la s√©curit√©, et l'observabilit√©.

Si besoin d'exemples de refactoring pour la prod, ou d'approfondir un point (ex : injection du pool, gestion avanc√©e des timeouts, monitoring), voir avec l'√©quipe ou demander un accompagnement technique. 